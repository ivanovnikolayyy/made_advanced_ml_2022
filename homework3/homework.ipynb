{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "673deb6b",
   "metadata": {},
   "source": [
    "# Продвинутое машинное обучение: Домашнее задание 3\n",
    "\n",
    "Третье домашнее задание посвящено достаточно простой, но, надеюсь, интересной задаче, в которой потребуется творчески применить методы сэмплирования. Как всегда, любые комментарии, новые идеи и рассуждения на тему категорически приветствуются.\n",
    "\n",
    "В этом небольшом домашнем задании мы попробуем улучшить метод Шерлока Холмса. Как известно, в рассказе The Adventure of the Dancing Men великий сыщик расшифровал загадочные письмена, которые выглядели примерно так:\n",
    "\n",
    "![](img/dancing_men.png)\n",
    "\n",
    "Пользовался он для этого так называемым частотным методом: смотрел, какие буквы чаще встречаются в зашифрованных текстах, и пытался подставить буквы в соответствии с частотной таблицей: E — самая частая и так далее.\n",
    "\n",
    "В этом задании мы будем разрабатывать более современный и продвинутый вариант такого частотного метода. В качестве корпусов текстов для подсчётов частот можете взять что угодно, но для удобства вот вам “Война и мир” по-русски и по-английски:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412100b5",
   "metadata": {},
   "source": [
    "## 1. Baseline\n",
    "\n",
    "Реализуйте базовый частотный метод по Шерлоку Холмсу:\n",
    "\n",
    "- подсчитайте частоты букв по корпусам (пунктуацию и капитализацию можно просто опустить, а вот пробелы лучше оставить);\n",
    "- возьмите какие-нибудь тестовые тексты (нужно взять по меньшей мере 2-3 предложения, иначе вряд ли сработает), зашифруйте их посредством случайной перестановки символов;\n",
    "- расшифруйте их таким частотным методом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cc31155",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "from typing import List, Dict, Callable\n",
    "from collections import Counter\n",
    "\n",
    "import tqdm\n",
    "import numpy as np\n",
    "\n",
    "RUSSIAN_ALPHABET = 'абвгдеёжзийклмнопрстуфхцчшщъыьэюя '\n",
    "ENGLISH_ALPHABET = 'abcdefghijklmnopqrstuvwxyz '\n",
    "\n",
    "\n",
    "def read_texts(data_path: str) -> List[str]:\n",
    "    with open(data_path, \"r\") as input_stream:\n",
    "        texts = input_stream.read().splitlines()\n",
    "    \n",
    "    return texts\n",
    "\n",
    "\n",
    "def preprocess_rus(text: str):\n",
    "    text = re.sub(r'[^а-ё ]+', '', text.lower())\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def preprocess_eng(text: str):\n",
    "    text = re.sub(r'[^a-z ]+', '', text.lower())\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def preprocess_texts(\n",
    "    texts: List[str], first_sentence: str = '', last_sentence: str = '', alphabet: str = 'rus'\n",
    ") -> str:\n",
    "\n",
    "    if alphabet == 'rus':\n",
    "        texts = [preprocess_rus(text) for text in texts]\n",
    "    elif alphabet == 'eng':\n",
    "        texts = [preprocess_eng(text) for text in texts]\n",
    "    else:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    preprocessed = [text for text in texts if text]\n",
    "\n",
    "    if first_sentence:\n",
    "        index_first = texts.index(first_sentence)\n",
    "        texts = texts[index_first:]\n",
    "\n",
    "    if last_sentence:\n",
    "        index_end = texts.index(last_sentence)\n",
    "        texts = texts[:index_end]\n",
    "    \n",
    "    texts = ' '.join(texts)\n",
    "\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e67f0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data/AnnaKarenina.txt\"\n",
    "first_sentence = \"все счастливые семьи похожи друг на друга каждая несчастливая семья несчастлива посвоему\"\n",
    "last_sentence = \"примечания\"\n",
    "\n",
    "texts = read_texts(data_path)\n",
    "corpus = preprocess_texts(texts, first_sentence, last_sentence, 'rus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "837ffad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path = \"data/WarAndPeace.txt\"\n",
    "# first_sentence = \"часть первая\"\n",
    "# last_sentence = \"\"\n",
    "\n",
    "# texts = read_texts(data_path)\n",
    "# corpus = preprocess_texts(texts, first_sentence, last_sentence, 'rus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a3f1bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path = \"data/WarAndPeaceEng.txt\"\n",
    "# first_sentence = \"well prince so genoa and lucca are now just family estates of the\"\n",
    "# last_sentence = \"end of the project gutenberg ebook of war and peace by leo tolstoy\"\n",
    "\n",
    "# texts = read_texts(data_path)\n",
    "# corpus = preprocess_texts(texts, first_sentence, last_sentence, 'eng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e3ad459",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_from_corpus(corpus: str, num_words: int):\n",
    "    words = corpus.split()\n",
    "    index_from = random.randint(0, len(words) - num_words)\n",
    "    sample = \" \".join(words[index_from: index_from + num_words])\n",
    "    \n",
    "    return sample\n",
    "\n",
    "\n",
    "def encode_chars(text: str, alphabet_from: str, alphabet_to: str = None):\n",
    "    if alphabet_to is None:\n",
    "        alphabet_to = alphabet_from\n",
    "    \n",
    "    permutation = np.random.permutation(list(alphabet_from))\n",
    "    encoding = dict(zip(permutation, alphabet_to))\n",
    "    encoded_text = ''.join(map(encoding.get, text))\n",
    "    \n",
    "    return encoded_text\n",
    "\n",
    "\n",
    "class CharDecoder:\n",
    "    def __init__(self, corpus: str):\n",
    "        self.corpus = corpus\n",
    "        self.corpus_chars = self.get_sorted_chars(self.corpus)\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_sorted_chars(text: str) -> List[chr]:\n",
    "        sorted_chars = [item[0] for item in Counter(text).most_common()]\n",
    "        \n",
    "        return sorted_chars\n",
    "    \n",
    "    def decode(self, encoded_text: str) -> str:       \n",
    "        text_chars = self.get_sorted_chars(encoded_text)\n",
    "        inverse_encoding = dict(zip(text_chars, self.corpus_chars))\n",
    "        decoded_text = ''.join(map(inverse_encoding.get, encoded_text))\n",
    "        \n",
    "        return decoded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df14360c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'тем дружески грубым тоном на который нельзя было сердиться ну проси же скорее сказал облонский морщась от досады просительница штабскапитанша калинина просила о невозможном и бестолковом но степан аркадьич по своему обыкновению усадил ее внимательно не перебивая выслушал ее и дал ей подробный совет к кому и как обратиться и даже бойко и складно своим крупным растянутым красивым и четким почерком написал ей записочку к лицу которое могло ей пособить отпустив штабскапитаншу степан аркадьич взял шляпу и остановился припоминая не забыл ли чего оказалось что он ничего не забыл кроме того что хотел забыть жену ах да он опустил голову'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = get_text_from_corpus(corpus, num_words=100)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f59dba76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ясъёоыцнсжбвёуыцчтъёяэдэъёдеёбэяэытзёдсьгихёчтьэёжсыовягжхёдцёпыэжвёнсёжбэыссёжбеиеьёэчьэджбвзёъэыйежгёэяёоэжеотёпыэжвясьгдвреёюяечжбепвяедюеёбеьвдвдеёпыэжвьеёэёдсмэиъэндэъёвёчсжяэьбэмэъёдэёжяспедёеыбеогвшёпэёжмэсъцёэчтбдэмсдв ёцжеовьёссёмдвъеясьгдэёдсёпсысчвмехёмтжьцюеьёссёвёоеьёсзёпэоыэчдтзёжэмсяёбёбэъцёвёбебёэчыеявягжхёвёоенсёчэзбэёвёжбьеодэёжмэвъёбыцпдтъёыежяхдцятъёбыежвмтъёвёшсябвъёпэшсыбэъёдепвжеьёсзёиепвжэшбцёбёьврцёбэяэыэсёъэуьэёсзёпэжэчвягёэяпцжявмёюяечжбепвяедюцёжяспедёеыбеогвшёмихьёюьхпцёвёэжяедэмвьжхёпывпэъвдехёдсёиечтьёьвёшсуэёэбеиеьэжгёшяэёэдёдвшсуэёдсёиечтьёбыэъсёяэуэёшяэёкэясьёиечтягёнсдцёекёоеёэдёэпцжявьёуэьэмц'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text = encode_chars(text, RUSSIAN_ALPHABET)\n",
    "encoded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47653c4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'снд ьрмшнила жрмуяд сотод те лосоряз тнвыгб уяво инрьасыиб тм кроиа шн илорнн илегев оувотилаз дорэеиы ос ьоиеья кроиаснвытахе йсеуилекасетйе леватате кроиаве о тнпогдоштод а унисовлопод то иснкет ерлеьыач ко ипондм оуялтопнтащ миеьав нн птадеснвыто тн кнрнуапеб пяивмйев нн а ьев нз коьроутяз иопнс л лодм а лел оуресасыиб а ьешн уозло а илвеьто ипоад лрмктяд реисбтмсяд лреиапяд а чнслад кочнрлод текаиев нз гекаиочлм л вахм лосорон дожво нз коиоуасы оскмисап йсеуилекасетйм иснкет ерлеьыач пгбв йвбкм а оисетопавиб кракодатеб тн геуяв ва чнжо олегевоиы чсо от тачнжо тн геуяв лродн сожо чсо юоснв геуясы шнтм ею ье от окмисав жовопм'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_decoder = CharDecoder(corpus)\n",
    "decoded_text = char_decoder.decode(encoded_text)\n",
    "decoded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e8e6aa53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_score(text1, text2):\n",
    "    \"\"\"Процент корректно расшифрованных букв\"\"\"\n",
    "    \n",
    "    correct = sum([a == b for a, b in zip(text1, text2)])\n",
    "    score = correct / len(text1)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "16984795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30551181102362207"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(text, decoded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1dd2a0b",
   "metadata": {},
   "source": [
    "## 2. Bigrams\n",
    "\n",
    "Вряд ли в результате получилась такая уж хорошая расшифровка, разве что если вы брали в качестве тестовых данных целые рассказы. Но и Шерлок Холмс был не так уж прост: после буквы E, которая действительно выделяется частотой, дальше он анализировал уже конкретные слова и пытался угадать, какими они могли бы быть. Я не знаю, как запрограммировать такой интуитивный анализ, так что давайте просто сделаем следующий логический шаг:\n",
    "\n",
    "- подсчитайте частоты биграмм (т.е. пар последовательных букв) по корпусам;\n",
    "- проведите тестирование аналогично п.1, но при помощи биграмм\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf0698fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigramsDecoder:\n",
    "    def __init__(self, corpus: str):\n",
    "        self.corpus = corpus\n",
    "        self.corpus_bigrams = self.get_sorted_bigrams(self.corpus)\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_bigrams(text: str) -> List[str]:\n",
    "        bigrams = [text[i: i + 2] for i in range(0, len(text) - 1, 2)]\n",
    "\n",
    "        return bigrams\n",
    "\n",
    "    def get_sorted_bigrams(self, text: str) -> List[chr]:\n",
    "        bigrams = self.get_bigrams(text)\n",
    "        bigrams = [item[0] for item in Counter(bigrams).most_common()]\n",
    "\n",
    "        return bigrams\n",
    "    \n",
    "    def decode(self, encoded_text: str) -> str:       \n",
    "        text_bigrams = self.get_sorted_bigrams(encoded_text)\n",
    "        inverse_encoding = dict(zip(text_bigrams, self.corpus_bigrams))\n",
    "        decoded_text = ''.join(map(inverse_encoding.get, text_bigrams))\n",
    "        \n",
    "        return decoded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ed21f87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'о е а и  н с вто п о ия наь стнеално к  онгопокакола тни довл енй вом  боту рора чтьпрослоелн  морваза еоллев ерлиретатеомскк етогилвичтдеант рисеы  удааказбыве затинжеодемит ртиесегдо ласльвсю обче г амоавсяой эмесьэтннимс мукиныивх миылтвей жслмаоеаянуеведтрвыиеамар ясошееерухочааддипебеисзничбоожсвдусаняияужекляизспидоч хокикшиднуддр'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams_decoder = BigramsDecoder(corpus)\n",
    "decoded_text = bigrams_decoder.decode(encoded_text)\n",
    "decoded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3bac3956",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03622047244094488"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(text, decoded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329af951",
   "metadata": {},
   "source": [
    "## 3. MCMC on bigrams\n",
    "\n",
    "Но и это ещё не всё: биграммы скорее всего тоже далеко не всегда работают. Основная часть задания — в том, как можно их улучшить:\n",
    "\n",
    "- предложите метод обучения перестановки символов в этом задании, основанный на MCMC-сэмплировании, но по-прежнему работающий на основе статистики биграмм;\n",
    "- реализуйте и протестируйте его, убедитесь, что результаты улучшились."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e5ca3792",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCMCBiramsDecoder(BigramsDecoder):\n",
    "    def __init__(self, corpus: str, alphabet_from: str, alphabet_to: str = None):\n",
    "        super().__init__(corpus)\n",
    "        \n",
    "        self.bigrams_freq = self.get_bigrams_freq(corpus)\n",
    "        self.default_freq =  min(self.bigrams_freq.values())\n",
    "\n",
    "        if alphabet_to is None:\n",
    "            alphabet_to = alphabet_from\n",
    "\n",
    "        self.alphabet_from = list(alphabet_from)\n",
    "        self.alphabet_to = list(alphabet_to)\n",
    "    \n",
    "    def get_bigrams_freq(self, text: str) -> Dict[str, float]:\n",
    "        bigrams = self.get_bigrams(text)\n",
    "        counts = dict(Counter(bigrams).most_common())\n",
    "        \n",
    "        smoothing_coef = len(text) + len(set(text)) ** 2\n",
    "        freq = {bigram: count / smoothing_coef for bigram, count in counts.items()}\n",
    "        \n",
    "        return freq\n",
    "\n",
    "    def text_log_proba(self, text: str):\n",
    "        log_proba = 0\n",
    "        for i in range(len(text) - 1):\n",
    "            bigram = text[i: i + 2]\n",
    "            bigram_freq = self.bigrams_freq.get(bigram, self.default_freq)\n",
    "            log_proba += np.log(bigram_freq)\n",
    "        \n",
    "        return log_proba\n",
    "    \n",
    "    \n",
    "    def decode(self, encoded_text: str, num_trials: int = 10, num_steps: int = 3000) -> str:\n",
    "        best_log_proba = float(\"-inf\")\n",
    "        best_inverse_encoding = None\n",
    "        \n",
    "        for trial in tqdm.tqdm(range(num_trials)):\n",
    "            # начнем с прямого отображения\n",
    "            alphabet = self.alphabet_to.copy()\n",
    "            inverse_encoding = dict(zip(self.alphabet_from, alphabet))\n",
    "            decoded_text = ''.join(map(inverse_encoding.get, encoded_text))\n",
    "            log_proba = self.text_log_proba(decoded_text)\n",
    "            \n",
    "            for step in range(num_steps):\n",
    "                # будем случайным образом менять порядок биграм в корпусе\n",
    "                new_alphabet = alphabet.copy()\n",
    "                i, j = np.random.choice(len(new_alphabet), size=2, replace=False)\n",
    "                new_alphabet[i], new_alphabet[j] = new_alphabet[j], new_alphabet[i]\n",
    "                \n",
    "                # считаем логарифм правдоподобия\n",
    "                new_inverse_encoding = dict(zip(self.alphabet_from, new_alphabet))                \n",
    "                new_decoded_text = ''.join(map(new_inverse_encoding.get, encoded_text))\n",
    "                new_log_proba = self.text_log_proba(new_decoded_text)\n",
    "\n",
    "                # получаем вероятность\n",
    "                p = np.exp(new_log_proba - log_proba)\n",
    "                if p > random.random():\n",
    "                    log_proba = new_log_proba\n",
    "                    inverse_encoding = new_inverse_encoding\n",
    "                    decoded_text = new_decoded_text\n",
    "                    alphabet = new_alphabet\n",
    "            \n",
    "            if log_proba > best_log_proba:\n",
    "                best_log_proba = log_proba\n",
    "                best_inverse_encoding = inverse_encoding\n",
    "        \n",
    "        decoded_text = ''.join(map(best_inverse_encoding.get, encoded_text))\n",
    "        \n",
    "        return decoded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7711fe8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:08<00:13,  2.18s/it]<ipython-input-35-0017bd4f79a6>:56: RuntimeWarning: overflow encountered in exp\n",
      "  p = np.exp(new_log_proba - log_proba)\n",
      "100%|██████████| 10/10 [00:21<00:00,  2.17s/it]\n"
     ]
    }
   ],
   "source": [
    "mcmc_bigram_decoder = MCMCBiramsDecoder(corpus, RUSSIAN_ALPHABET)\n",
    "decoded_text = mcmc_bigram_decoder.decode(encoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "15708a9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'тем дружески грубым тоном на который нельзя было сердиться ну проси же скорее сказал облонский морщась от досады просительница штабскапитанша калинина просила о невозможном и бестолковом но степан аркадьич по своему обыкновению усадил ее внимательно не перебивая выслушал ее и дал ей подробный совет к кому и как обратиться и даже бойко и складно своим крупным растянутым красивым и четким почерком написал ей записочку к лицу которое могло ей пособить отпустив штабскапитаншу степан аркадьич взял шляпу и остановился припоминая не забыл ли чего оказалось что он ничего не забыл кроме того что хотел забыть жену ах да он опустил голову'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6d44ec80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(text, decoded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b52b98",
   "metadata": {},
   "source": [
    "## 4. Predict\n",
    "\n",
    "Расшифруйте сообщение:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2e825bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_text = \"←⇠⇒↟↹↷⇊↹↷↟↤↟↨←↹↝⇛⇯↳⇴⇒⇈↝⇊↾↹↟⇒↟↹⇷⇛⇞↨↟↹↝⇛⇯↳⇴⇒⇈↝⇊↾↹↨←⇌⇠↨↹⇙↹⇸↨⇛↙⇛↹⇠⇛⇛↲⇆←↝↟↞↹⇌⇛↨⇛⇯⇊↾↹⇒←↙⇌⇛↹⇷⇯⇛⇞↟↨⇴↨⇈↹⇠⇌⇛⇯←←↹↷⇠←↙⇛↹↷⇊↹↷⇠←↹⇠↤←⇒⇴⇒↟↹⇷⇯⇴↷↟⇒⇈↝⇛↹↟↹⇷⇛⇒⇙⇞↟↨←↹↳⇴⇌⇠↟↳⇴⇒⇈↝⇊↾↹↲⇴⇒⇒↹⇰⇴↹⇷⇛⇠⇒←↤↝←←↹⇞←↨↷←⇯↨⇛←↹⇰⇴↤⇴↝↟←↹⇌⇙⇯⇠⇴↹↘⇛↨↞↹⇌⇛↝←⇞↝⇛↹↞↹↝↟⇞←↙⇛↹↝←↹⇛↲←⇆⇴⇏\"\n",
    "unknown_alphabet = list(set(unknown_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0a1b1d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:27<00:00,  2.76s/it]\n"
     ]
    }
   ],
   "source": [
    "mcmc_bigram_decoder = MCMCBiramsDecoder(corpus, alphabet_from=unknown_alphabet, alphabet_to=RUSSIAN_ALPHABET)\n",
    "decoded_text = mcmc_bigram_decoder.decode(unknown_text, num_steps=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c02ef3ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'если вы вимите нордальный или почти нордальный текст у этого сообщения который легко прочитать скорее всего вы все смелали правильно и получите даксидальный балл за послемнее четвертое замание курса хотя конечно я ничего не обещаж'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f51ea54",
   "metadata": {},
   "source": [
    "## 5*. Trigrams\n",
    "\n",
    "Бонус: а что если от биграмм перейти к триграммам (тройкам букв) или даже больше? Улучшатся ли результаты? Когда улучшатся, а когда нет? Чтобы ответить на этот вопрос эмпирически, уже может понадобиться погенерировать много тестовых перестановок и последить за метриками, глазами может быть и не видно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa63d9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae6dc33",
   "metadata": {},
   "source": [
    "## 6*. Applications\n",
    "Какие вы можете придумать применения для этой модели? Пляшущие человечки ведь не так часто встречаются в жизни (хотя встречаются! и это самое потрясающее во всей этой истории, но об этом я расскажу потом).\n",
    "\n",
    "Можно попробовать применить такую зашифровку с последующей расшифровкой в качестве аугментации (добавление шума) в некоторый текстовый корпус. Тогда скорее всего будет меньше вероятность переобучиться на некоторые n-граммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d95288",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-mipt",
   "language": "python",
   "name": "ml-mipt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
